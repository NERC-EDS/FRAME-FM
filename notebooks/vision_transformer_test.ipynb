{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1516c8e2",
   "metadata": {},
   "source": [
    "# Multimodal Masked Autoencoder test\n",
    "\n",
    "Motivated by [NASA and IBM's Prithvi](https://arxiv.org/abs/2412.02732) and [EPFL's MultiMAE](https://arxiv.org/abs/2204.01678), we seek to construct a [Vision Transformer](https://arxiv.org/abs/2010.11929)-based Multimodal [Masked Autoencoder](https://arxiv.org/pdf/2111.06377), capable of encoding combinations of temporal, spatial, and spatiotemporal data. We test the principle using the [Moving MNIST dataset](https://www.cs.toronto.edu/~nitish/unsupervised_video/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39019c87-9122-402a-9c11-c576dfbc1d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/gws/ssde/j25b/eds_ai/frame-fm/code/envs/torch-basic/lib/python3.12/site-packages\")\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8f409fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gws/ssde/j25b/eds_ai/frame-fm/code/envs/anemoi_env_nb/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from pytorch_lightning import Trainer\n",
    "import sys\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, default_collate, RandomSampler\n",
    "from torchvision import datasets\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "from src.FRAME_FM.models.mmmae import MultimodalMaskedAutoencoder\n",
    "\n",
    "import os\n",
    "USER = os.getenv(\"USER\", \"nobody\")\n",
    "\n",
    "project_directory = Path(\"/gws/ssde/j25b/eds_ai/frame-fm/data/inputs\")\n",
    "checkpoint_path = Path(f\"/gws/ssde/j25b/eds_ai/frame-fm/users/{USER}/model-checkpoints\")\n",
    "checkpoint_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def divide_batch(batch):\n",
    "    batch_frames = default_collate(batch).transpose(1, 2) / 8\n",
    "    batch_frame0 = batch_frames[:, :, 0]\n",
    "    batch_mean_x = torch.inner(torch.linspace(0, 1, 64), batch_frames.mean(dim=-1))\n",
    "    batch_mean_x = batch_mean_x / batch_frames.mean(dim=-1).sum(dim=-1)\n",
    "    return [batch_frames, batch_frame0, batch_mean_x]\n",
    "\n",
    "def construct_moving_mnist_dataloader(directory, train=True):\n",
    "    dataset = datasets.MovingMNIST(directory, download=True)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        sampler=RandomSampler(range(9000)) if train else range(9000, 10000),\n",
    "        batch_size=16,\n",
    "        drop_last=True,\n",
    "        collate_fn=divide_batch,\n",
    "        )\n",
    "    return dataloader\n",
    "\n",
    "dataloader_train = construct_moving_mnist_dataloader(project_directory, train=True)\n",
    "dataloader_test = construct_moving_mnist_dataloader(project_directory, train=False)\n",
    "\n",
    "mmmae = MultimodalMaskedAutoencoder(\n",
    "    input_shapes=[(20, 64, 64), (64, 64), (20,)],  # Shapes of inputs (in pixels)\n",
    "    n_channels=[1, 1, 1],  # Number of channels of inputs\n",
    "    patch_shapes=[(4, 8, 8), (8, 8), (4,)],  # Shapes of patches over which attention is to operate\n",
    "    encoder_embed_dim=8,  # Number of dimensions into which each patch is embedded\n",
    "    encoder_depth=16,  # Number of attention layers for encoding\n",
    "    encoder_num_heads=4,  # Number of attention heads per encoding layer\n",
    "    decoder_embed_dim=4,  # Number of dimensions from which to reconstruct each patch\n",
    "    decoder_depth=4,  # Number of attention layers for decoding\n",
    "    decoder_num_heads=4,  # Number of attention heads per decoding layer\n",
    "    mlp_ratio=4.,  # Ratio between dimensions of MLP layer and of embedding\n",
    "    norm_layer=torch.nn.LayerNorm,  # Class of normalisation layer\n",
    "    norm_token_loss=False,  # Whether to normalise target pixels in loss calculation\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "594cd229-26a8-4fc7-9351-72e3f7400a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "/gws/ssde/j25b/eds_ai/frame-fm/code/envs/torch-basic/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "ğŸ’¡ Tip: For seamless cloud logging and experiment tracking, try installing [litlogger](https://pypi.org/project/litlogger/) to enable LitLogger, which logs metrics and artifacts automatically to the Lightning Experiments platform.\n",
      "ğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "You are using a CUDA device ('NVIDIA A100-SXM4-40GB MIG 1g.10gb') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name            </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type       </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> FLOPs </span>â”ƒ\n",
       "â”¡â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>â”‚ input_embedders â”‚ ModuleList â”‚  8.9 K â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>â”‚ blocks          â”‚ ModuleList â”‚ 14.0 K â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>â”‚ norm            â”‚ LayerNorm  â”‚     16 â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>â”‚ decoder_embed   â”‚ Linear     â”‚     36 â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>â”‚ decoder_blocks  â”‚ ModuleList â”‚    976 â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span>â”‚ decoder_norm    â”‚ LayerNorm  â”‚      8 â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span>â”‚ other params    â”‚ n/a        â”‚     12 â”‚ n/a   â”‚   n/a â”‚\n",
       "â””â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mName           \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mType      \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mFLOPs\u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0mâ”‚ input_embedders â”‚ ModuleList â”‚  8.9 K â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0mâ”‚ blocks          â”‚ ModuleList â”‚ 14.0 K â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0mâ”‚ norm            â”‚ LayerNorm  â”‚     16 â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0mâ”‚ decoder_embed   â”‚ Linear     â”‚     36 â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0mâ”‚ decoder_blocks  â”‚ ModuleList â”‚    976 â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m5\u001b[0m\u001b[2m \u001b[0mâ”‚ decoder_norm    â”‚ LayerNorm  â”‚      8 â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m \u001b[0m\u001b[2m \u001b[0mâ”‚ other params    â”‚ n/a        â”‚     12 â”‚ n/a   â”‚   n/a â”‚\n",
       "â””â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 19.2 K                                                                                           \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 4.7 K                                                                                        \n",
       "<span style=\"font-weight: bold\">Total params</span>: 23.9 K                                                                                               \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 458                                                                                         \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total FLOPs</span>: 0                                                                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 19.2 K                                                                                           \n",
       "\u001b[1mNon-trainable params\u001b[0m: 4.7 K                                                                                        \n",
       "\u001b[1mTotal params\u001b[0m: 23.9 K                                                                                               \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 458                                                                                         \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal FLOPs\u001b[0m: 0                                                                                                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/gws/ssde/j25b/eds_ai/frame-fm/code/envs/anemoi_env_nb/lib/python3.12/site-packages/rich/live.py:256: UserWarning: \n",
       "install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/gws/ssde/j25b/eds_ai/frame-fm/code/envs/anemoi_env_nb/lib/python3.12/site-packages/rich/live.py:256: UserWarning: \n",
       "install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/gws/ssde/j25b/eds_ai/frame-fm/code/envs/torch-basic/lib/python3.12/site-packages/pytorch_lightning/utilities/_pytr\n",
       "ee.py:21: `isinstance(treespec, LeafSpec)` is deprecated, use `isinstance(treespec, TreeSpec) and \n",
       "treespec.is_leaf()` instead.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/gws/ssde/j25b/eds_ai/frame-fm/code/envs/torch-basic/lib/python3.12/site-packages/pytorch_lightning/utilities/_pytr\n",
       "ee.py:21: `isinstance(treespec, LeafSpec)` is deprecated, use `isinstance(treespec, TreeSpec) and \n",
       "treespec.is_leaf()` instead.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/gws/ssde/j25b/eds_ai/frame-fm/code/envs/torch-basic/lib/python3.12/site-packages/pytorch_lightning/trainer/connect\n",
       "ors/data_connector.py:434: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=63` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/gws/ssde/j25b/eds_ai/frame-fm/code/envs/torch-basic/lib/python3.12/site-packages/pytorch_lightning/trainer/connect\n",
       "ors/data_connector.py:434: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=63` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/gws/ssde/j25b/eds_ai/frame-fm/code/envs/torch-basic/lib/python3.12/site-packages/pytorch_lightning/trainer/connect\n",
       "ors/data_connector.py:434: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=63` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/gws/ssde/j25b/eds_ai/frame-fm/code/envs/torch-basic/lib/python3.12/site-packages/pytorch_lightning/trainer/connect\n",
       "ors/data_connector.py:434: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=63` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mask_ratio = 0.5\n",
    "load_checkpoint = False\n",
    "epochs = 10\n",
    "\n",
    "if load_checkpoint and checkpoint_path.is_file():\n",
    "    mmmae.load_from_checkpoint(checkpoint_path / \"checkpoint.ckpt\")\n",
    "\n",
    "trainer = Trainer(max_epochs=epochs, default_root_dir=checkpoint_path)\n",
    "trainer.fit(model=mmmae, train_dataloaders=dataloader_train, val_dataloaders=dataloader_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0839ead",
   "metadata": {},
   "source": [
    "Results appear no better than random, but demonstrate clear dependence of predictions on the input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14eafb2b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "'widget' is not a recognised GUI loop or backend name",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/gws/ssde/j25b/eds_ai/frame-fm/code/envs/torch-basic/lib/python3.12/site-packages/matplotlib/backends/registry.py:407\u001b[39m, in \u001b[36mBackendRegistry.resolve_gui_or_backend\u001b[39m\u001b[34m(self, gui_or_backend)\u001b[39m\n\u001b[32m    406\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m407\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mresolve_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgui_or_backend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:  \u001b[38;5;66;03m# KeyError ?\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gws/ssde/j25b/eds_ai/frame-fm/code/envs/torch-basic/lib/python3.12/site-packages/matplotlib/backends/registry.py:369\u001b[39m, in \u001b[36mBackendRegistry.resolve_backend\u001b[39m\u001b[34m(self, backend)\u001b[39m\n\u001b[32m    368\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m gui \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m369\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m is not a recognised backend name\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    371\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m backend, gui \u001b[38;5;28;01mif\u001b[39;00m gui != \u001b[33m\"\u001b[39m\u001b[33mheadless\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: 'widget' is not a recognised backend name",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmatplotlib\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mwidget\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m inputs = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(dataloader_test))\n\u001b[32m      4\u001b[39m masked_inputs, preds = [], []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gws/ssde/j25b/eds_ai/frame-fm/code/envs/anemoi_env_nb/lib/python3.12/site-packages/IPython/core/interactiveshell.py:2511\u001b[39m, in \u001b[36mInteractiveShell.run_line_magic\u001b[39m\u001b[34m(self, magic_name, line, _stack_depth)\u001b[39m\n\u001b[32m   2509\u001b[39m     kwargs[\u001b[33m'\u001b[39m\u001b[33mlocal_ns\u001b[39m\u001b[33m'\u001b[39m] = \u001b[38;5;28mself\u001b[39m.get_local_scope(stack_depth)\n\u001b[32m   2510\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.builtin_trap:\n\u001b[32m-> \u001b[39m\u001b[32m2511\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2513\u001b[39m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[32m   2514\u001b[39m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[32m   2515\u001b[39m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[32m   2516\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gws/ssde/j25b/eds_ai/frame-fm/code/envs/anemoi_env_nb/lib/python3.12/site-packages/IPython/core/magics/pylab.py:103\u001b[39m, in \u001b[36mPylabMagics.matplotlib\u001b[39m\u001b[34m(self, line)\u001b[39m\n\u001b[32m     98\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m     99\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAvailable matplotlib backends: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    100\u001b[39m         % _list_matplotlib_backends_and_gui_loops()\n\u001b[32m    101\u001b[39m     )\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m     gui, backend = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshell\u001b[49m\u001b[43m.\u001b[49m\u001b[43menable_matplotlib\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgui\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    104\u001b[39m     \u001b[38;5;28mself\u001b[39m._show_matplotlib_backend(args.gui, backend)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gws/ssde/j25b/eds_ai/frame-fm/code/envs/anemoi_env_nb/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3789\u001b[39m, in \u001b[36mInteractiveShell.enable_matplotlib\u001b[39m\u001b[34m(self, gui)\u001b[39m\n\u001b[32m   3786\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib_inline\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend_inline\u001b[39;00m\n\u001b[32m   3788\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pylabtools \u001b[38;5;28;01mas\u001b[39;00m pt\n\u001b[32m-> \u001b[39m\u001b[32m3789\u001b[39m gui, backend = \u001b[43mpt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfind_gui_and_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgui\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpylab_gui_select\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3791\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m gui != \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3792\u001b[39m     \u001b[38;5;66;03m# If we have our first gui selection, store it\u001b[39;00m\n\u001b[32m   3793\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pylab_gui_select \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gws/ssde/j25b/eds_ai/frame-fm/code/envs/anemoi_env_nb/lib/python3.12/site-packages/IPython/core/pylabtools.py:349\u001b[39m, in \u001b[36mfind_gui_and_backend\u001b[39m\u001b[34m(gui, gui_select)\u001b[39m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    348\u001b[39m     gui = _convert_gui_to_matplotlib(gui)\n\u001b[32m--> \u001b[39m\u001b[32m349\u001b[39m     backend, gui = \u001b[43mbackend_registry\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresolve_gui_or_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgui\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    351\u001b[39m gui = _convert_gui_from_matplotlib(gui)\n\u001b[32m    352\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m gui, backend\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gws/ssde/j25b/eds_ai/frame-fm/code/envs/torch-basic/lib/python3.12/site-packages/matplotlib/backends/registry.py:409\u001b[39m, in \u001b[36mBackendRegistry.resolve_gui_or_backend\u001b[39m\u001b[34m(self, gui_or_backend)\u001b[39m\n\u001b[32m    407\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.resolve_backend(gui_or_backend)\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:  \u001b[38;5;66;03m# KeyError ?\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m409\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    410\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgui_or_backend\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m is not a recognised GUI loop or backend name\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mRuntimeError\u001b[39m: 'widget' is not a recognised GUI loop or backend name"
     ]
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "inputs = next(iter(dataloader_test))\n",
    "masked_inputs, preds = [], []\n",
    "mmmae.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    _, token_preds, mask = mmmae(inputs, mask_ratio=mask_ratio)\n",
    "\n",
    "start_id = 0\n",
    "for embedder, input, pred_tokens in zip(mmmae.input_embedders, inputs, token_preds):\n",
    "    input_mask = mask[:, start_id:start_id + embedder.n_patches]\n",
    "    masked_patches = torch.where(\n",
    "        torch.unsqueeze(input_mask, -1) == 0, embedder.tokenify(input), np.nan\n",
    "        )\n",
    "    masked_inputs.append(embedder.untokenify(masked_patches))\n",
    "    preds.append(embedder.untokenify(pred_tokens))\n",
    "\n",
    "fig, axs = plt.subplots(3, 3, figsize=[6, 6])\n",
    "axs[0, 0].set_title(\"Input\")\n",
    "axs[0, 1].set_title(\"Masked input\")\n",
    "axs[0, 2].set_title(\"Prediction\")\n",
    "plt_imgs = [ax.imshow(np.zeros([64, 64]), vmin=0, vmax=1) for ax in axs[0]]\n",
    "for ax_row in axs[:2]:\n",
    "    for ax in ax_row:\n",
    "        ax.set_axis_off()\n",
    "\n",
    "axs[1, 0].imshow(inputs[1][0, 0], vmin=0, vmax=1)\n",
    "axs[1, 1].imshow(masked_inputs[1][0, 0], vmin=0, vmax=1)\n",
    "axs[1, 2].imshow(preds[1][0, 0], vmin=0, vmax=1)\n",
    "axs[2, 0].plot(range(inputs[2].shape[-1]), inputs[2][0].flatten())\n",
    "axs[2, 1].plot(range(inputs[2].shape[-1]), masked_inputs[2][0].flatten())\n",
    "axs[2, 2].plot(range(inputs[2].shape[-1]), preds[2][0].flatten())\n",
    "axs[2, 0].set_ylim([0, 1])\n",
    "for ax in axs[2, 1:]:\n",
    "    ax.set_xlim(axs[2, 0].get_xlim())\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.set_yticklabels([])\n",
    "\n",
    "def animate(frame):\n",
    "    plt_imgs[0].set_array(inputs[0][0, 0, frame])\n",
    "    plt_imgs[1].set_array(masked_inputs[0][0, 0, frame])\n",
    "    plt_imgs[2].set_array(preds[0][0, 0, frame])\n",
    "    return plt_imgs\n",
    "\n",
    "animation = FuncAnimation(fig, animate, frames=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896456d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anemoi_env_nb",
   "language": "python",
   "name": "anemoi_env_nb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
